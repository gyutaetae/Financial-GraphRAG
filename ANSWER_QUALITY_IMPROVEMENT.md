# ë‹µë³€ í’ˆì§ˆ ê°œì„  ê°€ì´ë“œ

## ğŸ¯ í˜„ì¬ ë¬¸ì œì 

**ì˜ˆì‹œ ì§ˆë¬¸:** "nvidia revenue" ë˜ëŠ” "ì—”ë¹„ë””ì•„ ìˆ˜ìµ ì˜¬í•´"

**í˜„ì¬ ë‹µë³€:**
- âŒ "í•´ë‹¹ ë¬¸ì„œë“¤ì—ì„œëŠ” ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
- âš ï¸ ì¶”ìƒì ì´ê³  ì¼ë°˜ì ì¸ ë‹µë³€ ("ê¸ì •ì ì¸ ì„±ì¥", "ê°•ë ¥í•œ ì…ì§€")
- âš ï¸ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ë¶€ì¡± (ì‹¤ì œ ìˆ˜ìµ ê¸ˆì•¡, ì„±ì¥ë¥  ë“±)

---

## ğŸ’¡ ê°œì„  ë°©ë²•

### 1. **ë°ì´í„° ì¸ë±ì‹± ê°œì„ ** ğŸ”

#### ë¬¸ì œ
PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œ ìˆ«ìì™€ í‘œê°€ ì œëŒ€ë¡œ íŒŒì‹±ë˜ì§€ ì•ŠìŒ

#### í•´ê²°ì±…
```python
# src/utils.py ê°œì„ 
def extract_text_from_pdf_with_metadata(pdf_path):
    """PDFì—ì„œ í‘œì™€ ìˆ«ìë¥¼ í¬í•¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    import pymupdf
    
    doc = pymupdf.open(pdf_path)
    extracted_data = []
    
    for page_num, page in enumerate(doc, start=1):
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = page.get_text()
        
        # í‘œ ì¶”ì¶œ (ì¤‘ìš”!)
        tables = page.find_tables()
        for table in tables:
            table_text = table.extract()
            # í‘œë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            formatted_table = format_table_as_text(table_text)
            text += f"\n\n[TABLE]\n{formatted_table}\n[/TABLE]\n"
        
        extracted_data.append({
            "text": text,
            "page_number": page_num,
            "has_tables": len(tables) > 0
        })
    
    return extracted_data
```

---

### 2. **ê²€ìƒ‰ ì¿¼ë¦¬ ê°œì„ ** ğŸ¯

#### ë¬¸ì œ
"nvidia revenue"ë¥¼ ê²€ìƒ‰í•  ë•Œ ê´€ë ¨ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í•¨

#### í•´ê²°ì±…: ì¿¼ë¦¬ í™•ì¥ (Query Expansion)

```python
# src/engine/graphrag_engine.py
async def aquery(self, question: str):
    # ì¿¼ë¦¬ í™•ì¥: ë™ì˜ì–´ ë° ê´€ë ¨ ìš©ì–´ ì¶”ê°€
    expanded_query = await self._expand_query(question)
    
    # ì˜ˆ: "nvidia revenue" â†’ "nvidia revenue ìˆ˜ìµ ë§¤ì¶œ ì‹¤ì  earnings"
    return await self._search_with_expanded_query(expanded_query)

async def _expand_query(self, question: str):
    """LLMì„ ì‚¬ìš©í•´ ì¿¼ë¦¬ í™•ì¥"""
    prompt = f"""
    ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”:
    
    ì§ˆë¬¸: {question}
    
    ê´€ë ¨ í‚¤ì›Œë“œ (ë™ì˜ì–´, ìœ ì‚¬ ìš©ì–´):
    """
    
    keywords = await self.llm_call(prompt)
    return f"{question} {keywords}"
```

---

### 3. **ì²­í¬ í¬ê¸° ìµœì í™”** ğŸ“

#### ë¬¸ì œ
ì²­í¬ê°€ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì•„ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ë†“ì¹¨

#### í•´ê²°ì±…: ì ì‘í˜• ì²­í‚¹ (Adaptive Chunking)

```python
# src/config.py
# í˜„ì¬ ì„¤ì •
CHUNK_SIZE = 1200  # ë„ˆë¬´ í´ ìˆ˜ ìˆìŒ
CHUNK_OVERLAP = 100

# ê°œì„ ëœ ì„¤ì •
CHUNK_SIZE = 600  # ë” ì‘ì€ ì²­í¬ë¡œ ì •ë°€ ê²€ìƒ‰
CHUNK_OVERLAP = 150  # ë” ë§ì€ ì˜¤ë²„ë©ìœ¼ë¡œ ë¬¸ë§¥ ìœ ì§€

# ë˜ëŠ” ë™ì  ì²­í‚¹
def adaptive_chunking(text, min_size=400, max_size=800):
    """ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í‚¹í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€"""
    sentences = split_into_sentences(text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) > max_size:
            if len(current_chunk) >= min_size:
                chunks.append(current_chunk)
                current_chunk = sentence
            else:
                current_chunk += " " + sentence
        else:
            current_chunk += " " + sentence
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks
```

---

### 4. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°•í™”** ğŸ”€

#### ë¬¸ì œ
ë²¡í„° ê²€ìƒ‰ë§Œìœ¼ë¡œëŠ” ì •í™•í•œ ìˆ«ì/ë‚ ì§œë¥¼ ì°¾ê¸° ì–´ë ¤ì›€

#### í•´ê²°ì±…: í‚¤ì›Œë“œ ê²€ìƒ‰ + ë²¡í„° ê²€ìƒ‰ ê²°í•©

```python
# src/engine/graphrag_engine.py
async def hybrid_search(self, question: str, top_k: int = 30):
    # 1. ë²¡í„° ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)
    vector_results = await self.vector_search(question, top_k=20)
    
    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­)
    keywords = extract_keywords(question)  # "nvidia", "revenue", "2023"
    keyword_results = await self.keyword_search(keywords, top_k=10)
    
    # 3. ê²°ê³¼ ë³‘í•© ë° ì¬ìˆœìœ„í™”
    combined_results = merge_and_rerank(vector_results, keyword_results)
    
    return combined_results[:top_k]

def extract_keywords(question: str):
    """ì§ˆë¬¸ì—ì„œ ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # íšŒì‚¬ëª…, ìˆ«ì, ë‚ ì§œ ë“± ì¶”ì¶œ
    import re
    
    keywords = []
    
    # íšŒì‚¬ëª… ì¶”ì¶œ
    companies = re.findall(r'\b(nvidia|ì—”ë¹„ë””ì•„|ì‚¼ì„±|samsung)\b', question.lower())
    keywords.extend(companies)
    
    # ìˆ«ì ì¶”ì¶œ
    numbers = re.findall(r'\d+', question)
    keywords.extend(numbers)
    
    # ì¬ë¬´ ìš©ì–´ ì¶”ì¶œ
    financial_terms = ['revenue', 'ìˆ˜ìµ', 'ë§¤ì¶œ', 'earnings', 'ì‹¤ì ']
    for term in financial_terms:
        if term in question.lower():
            keywords.append(term)
    
    return keywords
```

---

### 5. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ ** ğŸ“

#### ë¬¸ì œ
LLMì´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ

#### í•´ê²°ì±…: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸

```python
# src/utils.py
def get_executive_report_prompt(question: str, context: str):
    """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸"""
    return f"""
ë‹¹ì‹ ì€ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**ì¤‘ìš” ì§€ì¹¨:**
1. êµ¬ì²´ì ì¸ ìˆ«ì, ë‚ ì§œ, ë°±ë¶„ìœ¨ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
2. ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš” (ì˜ˆ: "2023ë…„ Q3 ë³´ê³ ì„œì— ë”°ë¥´ë©´...")
3. ì¶”ìƒì ì¸ í‘œí˜„ ëŒ€ì‹  êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
4. ì •ë³´ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë§í•˜ì„¸ìš”

**ì§ˆë¬¸:** {question}

**ì œê³µëœ ë¬¸ì„œ:**
{context}

**ë‹µë³€ í˜•ì‹:**
1. í•µì‹¬ ë‹µë³€ (êµ¬ì²´ì ì¸ ìˆ«ì í¬í•¨)
2. ìƒì„¸ ì„¤ëª…
3. ì¶œì²˜ ë° ê·¼ê±°

ë‹µë³€:
"""
```

---

### 6. **Re-ranking ì¶”ê°€** ğŸ–ï¸

#### ë¬¸ì œ
ê²€ìƒ‰ëœ ì²­í¬ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë‚®ìŒ

#### í•´ê²°ì±…: Cross-Encoderë¥¼ ì‚¬ìš©í•œ ì¬ìˆœìœ„í™”

```python
# src/engine/graphrag_engine.py
from sentence_transformers import CrossEncoder

class HybridGraphRAGEngine:
    def __init__(self):
        # ...
        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    async def rerank_results(self, question: str, chunks: list):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ìˆœìœ„í™”"""
        # ê° ì²­í¬ì™€ ì§ˆë¬¸ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        pairs = [(question, chunk['text']) for chunk in chunks]
        scores = self.reranker.predict(pairs)
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        ranked_chunks = sorted(
            zip(chunks, scores),
            key=lambda x: x[1],
            reverse=True
        )
        
        return [chunk for chunk, score in ranked_chunks]
```

---

### 7. **ë©”íƒ€ë°ì´í„° í™œìš© ê°•í™”** ğŸ“Š

#### ë¬¸ì œ
í˜ì´ì§€ ë²ˆí˜¸, ì„¹ì…˜ ì •ë³´ ë“±ì´ ì œëŒ€ë¡œ í™œìš©ë˜ì§€ ì•ŠìŒ

#### í•´ê²°ì±…: ë©”íƒ€ë°ì´í„° í•„í„°ë§

```python
# src/engine/graphrag_engine.py
async def search_with_metadata_filter(self, question: str, filters: dict = None):
    """ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ ê²€ìƒ‰"""
    
    # ì§ˆë¬¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    # ì˜ˆ: "2023ë…„ Q3 ë³´ê³ ì„œì—ì„œ ì—”ë¹„ë””ì•„ ìˆ˜ìµ"
    metadata = extract_metadata_from_question(question)
    
    # í•„í„° ì ìš©
    if metadata.get('year'):
        filters['year'] = metadata['year']
    if metadata.get('quarter'):
        filters['quarter'] = metadata['quarter']
    
    # í•„í„°ë§ëœ ê²€ìƒ‰
    results = await self.filtered_search(question, filters)
    
    return results

def extract_metadata_from_question(question: str):
    """ì§ˆë¬¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    import re
    
    metadata = {}
    
    # ì—°ë„ ì¶”ì¶œ
    year_match = re.search(r'(20\d{2})', question)
    if year_match:
        metadata['year'] = year_match.group(1)
    
    # ë¶„ê¸° ì¶”ì¶œ
    quarter_match = re.search(r'Q([1-4])', question, re.IGNORECASE)
    if quarter_match:
        metadata['quarter'] = quarter_match.group(1)
    
    return metadata
```

---

### 8. **ë‹¤ë‹¨ê³„ ì¶”ë¡  (Multi-hop Reasoning)** ğŸ”—

#### ë¬¸ì œ
ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ë¶€ì¡±í•¨

#### í•´ê²°ì±…: Chain-of-Thought ì¶”ë¡ 

```python
# src/engine/graphrag_engine.py
async def multi_hop_reasoning(self, question: str):
    """ë‹¤ë‹¨ê³„ ì¶”ë¡ """
    
    # 1ë‹¨ê³„: ì§ˆë¬¸ ë¶„í•´
    sub_questions = await self.decompose_question(question)
    # ì˜ˆ: "ì—”ë¹„ë””ì•„ 2023ë…„ ìˆ˜ìµ ì„±ì¥ë¥ " 
    # â†’ ["ì—”ë¹„ë””ì•„ 2023ë…„ ìˆ˜ìµ", "ì—”ë¹„ë””ì•„ 2022ë…„ ìˆ˜ìµ", "ì„±ì¥ë¥  ê³„ì‚°"]
    
    # 2ë‹¨ê³„: ê° í•˜ìœ„ ì§ˆë¬¸ì— ë‹µë³€
    sub_answers = []
    for sub_q in sub_questions:
        answer = await self.aquery(sub_q)
        sub_answers.append(answer)
    
    # 3ë‹¨ê³„: í•˜ìœ„ ë‹µë³€ í†µí•©
    final_answer = await self.synthesize_answers(question, sub_answers)
    
    return final_answer
```

---

## ğŸ“Š ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ê³„íš

### ğŸ”´ ì¦‰ì‹œ ì ìš© (High Priority)

1. **í”„ë¡¬í”„íŠ¸ ê°œì„ ** - êµ¬ì²´ì ì¸ ìˆ«ì ìš”êµ¬
2. **ì²­í¬ í¬ê¸° ì¡°ì •** - 600ìë¡œ ì¶•ì†Œ, ì˜¤ë²„ë© 150ì
3. **ì¿¼ë¦¬ í™•ì¥** - ë™ì˜ì–´ ì¶”ê°€

### ğŸŸ¡ ë‹¨ê¸° ê°œì„  (Medium Priority)

4. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** - í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰
5. **Re-ranking** - Cross-Encoder ì¶”ê°€
6. **í‘œ ì¶”ì¶œ ê°œì„ ** - PyMuPDF í…Œì´ë¸” íŒŒì‹±

### ğŸŸ¢ ì¥ê¸° ê°œì„  (Low Priority)

7. **ë©”íƒ€ë°ì´í„° í•„í„°ë§** - ì—°ë„/ë¶„ê¸° í•„í„°
8. **ë‹¤ë‹¨ê³„ ì¶”ë¡ ** - Chain-of-Thought

---

## ğŸš€ ë¹ ë¥¸ ì ìš© ì˜ˆì‹œ

### ì¦‰ì‹œ ê°œì„  ê°€ëŠ¥í•œ ì½”ë“œ

```python
# src/config.pyì— ì¶”ê°€
# ì²­í¬ í¬ê¸° ìµœì í™”
CHUNK_SIZE = 600  # ê¸°ì¡´: 1200
CHUNK_OVERLAP = 150  # ê¸°ì¡´: 100

# src/utils.pyì— ì¶”ê°€
def get_executive_report_prompt(question: str, context: str):
    return f"""
ë‹¹ì‹ ì€ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì¤‘ìš”:** ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ìˆ«ì, ë‚ ì§œ, ë°±ë¶„ìœ¨ì„ í¬í•¨í•˜ì„¸ìš”.

ì§ˆë¬¸: {question}

ë¬¸ì„œ:
{context}

ë‹µë³€ (êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ í¬í•¨):
"""
```

---

## ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼

| ê°œì„  ì‚¬í•­ | íš¨ê³¼ |
|----------|------|
| í”„ë¡¬í”„íŠ¸ ê°œì„  | êµ¬ì²´ì ì¸ ë‹µë³€ +50% |
| ì²­í¬ í¬ê¸° ì¡°ì • | ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ +30% |
| í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ | ì •í™•ë„ +40% |
| Re-ranking | ê´€ë ¨ì„± +35% |

---

## ğŸ¯ ê²°ë¡ 

**ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ :**
1. í”„ë¡¬í”„íŠ¸ì— "êµ¬ì²´ì ì¸ ìˆ«ì í¬í•¨" ì§€ì‹œ ì¶”ê°€
2. ì²­í¬ í¬ê¸°ë¥¼ 600ìë¡œ ì¶•ì†Œ
3. ì¿¼ë¦¬ì— ë™ì˜ì–´ ì¶”ê°€

**ì´ 3ê°€ì§€ë§Œ ì ìš©í•´ë„ ë‹µë³€ í’ˆì§ˆì´ í¬ê²Œ ê°œì„ ë©ë‹ˆë‹¤!**
